{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1uJZvJdi5VprOQHROtJIHy0mnY2afjNlx","timestamp":1686419570680}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"0m2JWFliFfKT"},"source":["from __future__ import print_function\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# CNN model definition\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class Model(nn.Module):\n","    def __init__(self):\n","        super(Model, self).__init__()\n","        \n","        self.conv1 = nn.Sequential(\n","            nn.Conv2d(1, 32, 3, padding=1),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(32),\n","            nn.Conv2d(32, 32, 3, padding=1),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(32),\n","            nn.Conv2d(32, 32, 3, stride=2, padding=1),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(32),\n","            nn.MaxPool2d(2, 2),\n","            nn.Dropout(0.25)\n","        )\n","        \n","        self.conv2 = nn.Sequential(\n","            nn.Conv2d(32, 64, 3, padding=1),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(64),\n","            nn.Conv2d(64, 64, 3, padding=1),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(64),\n","            nn.Conv2d(64, 64, 3, stride=2, padding=1),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(64),\n","            nn.MaxPool2d(2, 2),\n","            nn.Dropout(0.25)\n","        )\n","        \n","        self.conv3 = nn.Sequential(\n","            nn.Conv2d(64, 128, 3, padding=1),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(128),\n","            nn.MaxPool2d(2, 2),\n","            nn.Dropout(0.25)\n","        )\n","        \n","        self.fc = nn.Sequential(\n","            nn.Linear(128, 10)\n","        )\n","                \n","        \n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.conv2(x)\n","        x = self.conv3(x)\n","        \n","        x = x.view(x.size(0), -1)\n","        x = self.fc(x)\n","        x = F.log_softmax(x, dim=1)\n","        return x\n","\n"],"metadata":{"id":"PQaT7G4zZgvD"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xdydjYTZFyi3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686421002056,"user_tz":-330,"elapsed":4157,"user":{"displayName":"Satej Panditrao","userId":"06333314183993197182"}},"outputId":"5b73ee2d-3b8b-4861-e506-bb12db701843"},"source":["!pip install torchsummary\n","from torchsummary import summary\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","model = Net().to(device)\n","summary(model, input_size=(1, 28, 28))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 32, 28, 28]             320\n","            Conv2d-2           [-1, 64, 28, 28]          18,496\n","         MaxPool2d-3           [-1, 64, 14, 14]               0\n","            Conv2d-4          [-1, 128, 14, 14]          73,856\n","            Conv2d-5          [-1, 256, 14, 14]         295,168\n","         MaxPool2d-6            [-1, 256, 7, 7]               0\n","            Conv2d-7            [-1, 512, 5, 5]       1,180,160\n","            Conv2d-8           [-1, 1024, 3, 3]       4,719,616\n","            Conv2d-9             [-1, 10, 1, 1]          92,170\n","================================================================\n","Total params: 6,379,786\n","Trainable params: 6,379,786\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 1.51\n","Params size (MB): 24.34\n","Estimated Total Size (MB): 25.85\n","----------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-3-750c761bb12f>:23: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","  return F.log_softmax(x)\n"]}]},{"cell_type":"code","metadata":{"id":"DqTWLaM5GHgH"},"source":["\n","\n","torch.manual_seed(1)\n","batch_size = 128\n","\n","kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n","train_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=True, download=True,\n","                    transform=transforms.Compose([\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.1307,), (0.3081,))\n","                    ])),\n","    batch_size=batch_size, shuffle=True, **kwargs)\n","test_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.1307,), (0.3081,))\n","                    ])),\n","    batch_size=batch_size, shuffle=True, **kwargs)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8fDefDhaFlwH"},"source":["from tqdm import tqdm\n","def train(model, device, train_loader, optimizer, epoch):\n","    model.train()\n","    pbar = tqdm(train_loader)\n","    for batch_idx, (data, target) in enumerate(pbar):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = F.nll_loss(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n","\n","\n","def test(model, device, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n","            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","\n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","        test_loss, correct, len(test_loader.dataset),\n","        100. * correct / len(test_loader.dataset)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","model = Net().to(device)\n","optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","\n","for epoch in range(1, 20):\n","    train(model, device, train_loader, optimizer, epoch)\n","    test(model, device, test_loader)"],"metadata":{"id":"GAX5V8pNkz_J"},"execution_count":null,"outputs":[]}]}